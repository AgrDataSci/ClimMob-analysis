---
title: "`r paste('Report of ClimMob project ', projname)`"
author: "ClimMob.net"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  word_document:
    reference_docx: word_style_template.docx
    toc: true
  html_document:
    toc: true
  pdf_document:
    toc: true
bibliography: ["climmob.bib"]
csl: citation_style.csl
---

```{r setup_opts, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      error = FALSE,
                      message=FALSE,
                      warning = FALSE)
```


# Introduction  

In agriculture, the local environmental conditions determine to a large degree which technological solutions are the most suitable. In dry soils, for example, drought-resistant crop varieties will outperform other varieties, but in wet soils these same varieties may do worse than most. Not only drought, but an entire range of problems including excessive heat, floods, new pests and diseases tend to intensify under climate change. This multitude of limiting factors requires multiple technological solutions, tested in diverse environments. 
 
Citizen science is based on the cooperation of 'citizen scientists' or observers (paid or unpaid). Researchers assign small tasks (observations, experiments) that, once completed and gathered, contribute with a great amount of information to science. One of the advantages of citizen science is that agricultural researchers can get access to many environments by crowdsourcing their experiments. As farmers contribute with their time, skills and knowledge to the investigation, researchers are able to do more tests than in a traditional experimental design. Also citizen scientists acquire new knowledge, abilities and information useful for future challenges of their work.

## ClimMob

The primary goal of ClimMob is to support the selection of innovative technologies (*e.g.* new crop varieties, management, new product). ClimMob serves to prepare and analyze citizen science experiments in which a large number of participants observe and compare different technological options under a wide range of conditions [@vanEtten2019tricot]. 
 
ClimMob software assigns a limited number of items (typically 3) to each participant, who will compare their performance. Each participant gets a different combination of items drawn from a much larger set of items (typically 15-25). Comparisons of this kind are thought to be a very reliable way to obtain data. Once the results of the small tasks have been collected, ClimMob builds an image of the whole set of assigned objects, combining all observations. ClimMob not only reconstructs the overall ordering of items, but also takes into account differences and similarities between participants and the conditions under which they observe (e.g. socio-economic and plot environmental traits). It assigns similar participants to groups that each corresponds among different group profiles. Groups are created on the basis of whichever items which have been collected, that are found to be significantly linked to the observed rankings.
 
ClimMob uses Plackett-Luce models to analyze ranking data with the R [@RCoreTeam] package 'PlackettLuce' [@Turner2020]. It automatically generates analytical reports, as well as individualized information sheets for each participant using the R packages 'knitr' [@knitr] and 'rmarkdown' [@rmarkdown]. Organizing the data relies on packages 'ClimMobTools' [@climmobtools], 'gosset' [@gosset], 'gtools' [@gtools], 'jsonlite' [@jsonlite], 'partykit' [@partykit], 'psychotools' [@psychotools] and 'qvcalc' [@qvcalc]. Summaries and data visualization are supported by packages 'igraph' [@igraph], 'ggparty' [@ggparty], 'ggplot2' [@ggplot2], 'ggrepel' [@ggrepel], 'gridExtra' [@gridExtra] 'leaflet' [@leaflet], 'multcompView' [@multcompView], 'patchwork' [@patchwork], 'png' [@png], 'plotrix' [@plotrix] and 'pls' [@pls].
 

## How to cite

If you publish any results generated with ClimMob, you should cite a number of articles as the package builds on various contributions. The crowdsourcing philosophy behind ClimMob is introduced by van Etten et al. (2019) [@vanEtten2019tricot]. It is important to mention that ClimMob is implemented in R, a free, open-source analysis software [@RCoreTeam]. Methodologically, if you report on the Plackett-Luce tree results, you should mention that ClimMob applies the Plackett-Luce model published by Turner et al. 2020 [@Turner2020]. To cite ClimMob itself, mention van Etten et al. (2020) [@climmob]. The workflow used to produce this report is documented by de Sousa et al. (2021) [@climmobanalysis].

\pagebreak

# Section 1: Headline results

Overall, there were `r nranker` `r rankers` registered to this project. Each `r ranker` assessed `r ncomp` different `r options` and ranked them in order of its '`r ovname`'. In addition, they also provided rankings for `r length(trait$name) -1` additional trait(s). 

```{r trait_drop}

trait_note <- ""

if (length(trait_dropped) > 0) {
  if(length(trait_dropped) > 1) {
    verb <- " were "
    adj <- " traits "
    noun <- " they "
  }else{
    verb <- " was "
    adj <- " trait "
    noun <- " it "
  }
  
  trait_note <- paste0("The", adj, paste(trait_dropped, collapse = ", "), verb, "not considered in this report because", noun, "did not surpass the thresholds of (1) having at least ", missper, " valid entries, and (2) that all the ", options, " are tested at least twice per given trait. Table 1.1. shows the traits analysed in this report.")
}
```

`r paste(trait_note, collapse='\n')`

\

```{r traits}
try(
kable(tbl_section1, 
      caption = paste0("Table 1.1. Summary of traits and valid answers used in this report."),
      row.names = FALSE,
      align = "l"),
silent = TRUE)

```

\

Figure 1.1 is a graphical representation of the information presented in Table 1.1, showing the number of valid answers received by each trait in each data collection moment in this project. 

\

```{r progress, dpi=dpi, fig.height=7, fig.width=10, fig.cap=paste0("Figure 1.1. Progress in data collection per data collection moment and trait evaluated in this project.")}
try(plot_tbl1)
```

\

```{r trial_map_statement}
trial_map_statement <- ""
if (isTRUE(geoTRUE)){
  trial_map_statement <- paste0("The map below shows the distribution ",
                               "of the trials in this project. If you registered ", 
                               "more than one GPS location per ", ranker, ", the map ",
                               "shows the GPS registry which had the largest number ",
                               "of valid GPS records. We used the GPS points from '", 
                               gsub("_lon", "", lon),"'. To respect ",
                               ranker, "'s privacy, the coordinates ",
                               "were clustered with a 0.05 arc-degree resolution. You can find ",
                               "the original coordinates in your ClimMob data.")
}
```

`r paste(trial_map_statement, collapse='\n')`

```{r map, dpi=dpi, out.width = '70%'}
if (isTRUE(geoTRUE)) {
  if (extension == "html") {
    trial_map
  }else{
    try(knitr::include_graphics(paste0(outputpath, "/", projname, "_trial_map.png")), silent = TRUE)
  }
}
```

\

```{r local}
usedlocal <- ""
if(tricotVSlocal) {
  usedlocal <- paste0("Additionally, ", rankers, " were asked to compare the ", length(items), " ", options, " against the local ", option, " currently used by them.")
}
```


Table 1.2 shows the `r length(items)` `r options` assessed within this project, with the frequency and percentage of `r rankers` who assessed each `r option`. `r usedlocal` If the `r options` have large names (> 10 characters) an abbreviation was applied across the figures in this report.

```{r itemtable}
try(kable(itemtable, 
          caption = paste0("Table 1.2. Frequency of ", options," assessed."),
          align = "l",
          row.names = FALSE), silent = TRUE)
```

\

Figure 1.2 shows that the `r options` are all connected to each other. That means that they all co-occurred at least once in an incomplete block of `r ncomp` `r options`. 

```{r network, dpi=dpi, fig.height=7, fig.width=7, fig.cap=paste0("Figure 1.2. Network representation of ", options, " tested in this project.")}
if (isTRUE("igraph" %in% class(net))){
 try(igraph::plot.igraph(net,
                    edge.arrow.size = 0.5), silent = TRUE)
}
```

\

## Overall differences in rankings

```{r stat_diff_statement}
# make the statement for the report about the statistical significance
stat_diff_statement <- paste0("This report takes the trait '", ovname, 
                              "' as the reference trait for the analysis.",
                              " A summary of the p-values testing the hypothesis ",
                              "that there were differences in the rankings for each ",
                              "trait, and the list of ", options, " which showed significant ",
                              "best and worst performance, are summarized in Table 1.3.")
```

`r paste(stat_diff_statement, collapse='\n')`

\

```{r summ_differences}
try(
  kable(ptab, 
      caption = paste0("Table 1.3. Summary of differences found in ",options," by trait."),
      row.names = FALSE),
  silent = TRUE)
```


\

## Correlation between the `r ovname` and the other traits

```{r relation_other_chrs} 
relation_other_chrs1 <- paste0("This report only assessed the trait '", ovname, "'.")
relation_other_chrs2 <- ""
if (isTRUE(nothertraits > 0)) {
relation_other_chrs1 <- 
  paste0("Table 1.4 shows, for each trait evaluated in the project, ", 
        "the frequency for which the rankings matched with the trait '", ovname, 
        "'. Best and worst agreement represent the percentage ", 
        "for which the best and worst ", option, " for the trait ", 
        "matched the best and worst '", ovname, "'. Complete ranking agreement ", 
        "shows the proportion of correlation on the full ranking with the trait '", 
        ovname, "' as reference using the Kendall correlation ", 
        "coefficient [@Kendall1938].")

relation_other_chrs2 <- 
  paste0("The trait that had the strongest ", 
        "relationship with '", ovname, "' was '", tolower(strongest_link[1]), 
        "'. Overall, the rankings for '",   tolower(strongest_link[1]), 
        "' matched the rankings for '", ovname, "' ",   tolower(strongest_link[2]),
        "% of the time. The trait that had the weakest ", 
        " relationship with '", ovname, "' was '",
         tolower(weakest_link[1]), "'. Overall, the rankings for '" ,  
        tolower(weakest_link[1]), "' matched the rankings for '", 
        ovname, "' " ,  tolower(weakest_link[2]), "% of the time.",
        " The correlation with the other traits is also shown in Figure 1.3.")

}
```

`r paste(relation_other_chrs1, collapse='\n')`

```{r agreement_table}
if (nothertraits > 0) {
try(
  kable(agreement_table,
      caption = paste0("Table 1.4. Correlation between '", ovname, 
                       "' and the other traits assessed in this project."),
      row.names = FALSE),
  silent = TRUE)
}
```

\

`r paste(relation_other_chrs2, collapse='\n')`


```{r correspondence, dpi=dpi,fig.height=agreem_h, fig.width=12, fig.cap= paste0("Figure 1.3. Correlation between individual traits and ", ovname, ".")}
if (nothertraits > 0) {
  plot(agreement) +
  theme_minimal() +  
  theme(axis.text.x = element_text(size = 10, color = "#000000"),
        axis.text.y = element_text(size = 10, color = "#000000"),
        strip.text.x = element_text(size = 11, color = "#000000", face = "bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  scale_fill_manual(values = c('#66c2a5','#fc8d62','#8da0cb'))
}
```

\

```{r pls_statement}
# partial least squares statement
pls_statement <- ""
if (isTRUE(dim(arrows)[[1]] > 0)) {
pls_statement <- 
    paste0("Partial least squares regression was used to determine ", 
          "relationship between the other traits and ", 
          "'", ovname , "'. The first two components ", 
          "recombining the specific traits ",
          "are able to explain the variability in '", ovname, "'. ",
          "The dashed line represents the '", ovname, 
          "' with an increase in performance as the x and y increase. ",
          "The ", option, " positioned close to the dashed line will ", 
          "be performing equally across all traits. ",
          "The ", option, " positioned further away from the dashed line, ",
          "on either side, will have varying performance ",
          "in different traits. Better performance in a given ",
          "trait will correspond with arrows pointing ",
          "in the direction away from the dashed line and worse ",
          "performance in traits directed on the opposite side.")
}

```

`r paste(pls_statement, collapse='\n')`

```{r plsplot, dpi=dpi,fig.height=6, fig.width=6, fig.cap= paste0("Figure 1.4. Partial least squares biplot of relationship between the tested ", options, " and the traits evaluated. The dashed line represents the '", ovname, "' with an increase in performance as the x and y increase.")}
if (isTRUE(dim(arrows)[[1]] > 0)) {
  try(plot(plsplot), silent = TRUE)
}
```

\pagebreak

# Section 2: `r Ovname`, data summary and exploratory analysis

## Assessment of `r options` 

Exploratory analysis within the following section summarises results from the rankings on '`r ovname`'. Results from other sections, and in the overall summary use Plackett-Luce models [@Turner2020]. Performance of each of the `r options` for '`r ovname`' is summarized in Table 2.1. 


```{r fav_table}
try(knitr::kable(fav_traits[[reference_trait]][[2]],
             row.names = FALSE,
             caption = paste0("Table 2.1. Favorability scores for '", 
                              ovname, "'." )), 
    silent = TRUE)
```

\

This shows the percentage of `r rankers` who assessed the `r options` as the best among the `r ncomp` `r options` they were provided, the percentage of `r rankers` who included the `r option` as their worst, the percentage of 'head-to-head contests' for which the `r option` won and the net *favorability* score (Figure 2.1). A score of +100 indicates the `r option` won all 'contests' it was involved in, a score of 0 indicates an equal number of wins and losses, a score of -100 indicates the `r option` lost all contests. 

```{r fav_plot, dpi=dpi, fig.height=favplot_h, fig.width=6, fig.cap= paste0("Figure 2.1. Net favorability scores for '", ovname, "'.")}
plot(fav_traits[[reference_trait]][[1]]) +
  xlab("") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 10, color = "#000000"),
        axis.text.y = element_text(size = 10, color = "#000000"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
```

\

```{r best_items}
best_items <- ""
if (isTRUE(nrow(fav_traits[[reference_trait]][[2]]) > 0)) {
  best_items <-
  paste("The", option, fav_traits[[reference_trait]][[2]][[1,1]], "was the 'best'", option, 
  " for the trait ", ovname, " being ranked highest by", 
  fav_traits[[reference_trait]][[2]][[1,3]], "of the" , 
  nranker, rankers, "who assessed this", option, ".")
}
```

`r paste(best_items, collapse = '\n')`

\

## Pairwise contests 

Figure 2.3 shows the outcomes of all pairwise contests between the `r options` included in the project for '`r ovname`'. Each panel shows the performance of one `r option` against all the other `r options`, and shows the percentage of the times in which the paneled `r option` was ranked above the other `r options` shown as bars. 

```{r contests_bars, dpi=dpi, fig.height=contest_h, fig.width=9, fig.cap= paste0("Figure 2.3. Head to head performance for '", ovname, "'.")}
plot(vic_traits[[reference_trait]]) +
  labs(x = "", y = "") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 10, color = "#000000"),
        axis.text.y = element_text(size = 10, color = "#000000"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
  
```

\

## Plackett-Luce Model estimates

\

Table 2.2 shows the results from the likelihood ratio test from the Plackett-Luce model for the trait '`r ovname`' of the different `r options`. The hypothesis being tested is that there is no difference in the assessments of any of the different `r options`.

```{r, aov1}
try(kable(aov_tables[[reference_trait]], 
      caption = paste0("Table 2.2. Likelihood ratio test results from fitted ", 
      "Plackett-Luce model with rankings from '", 
      ovname, "'."),
      row.names = FALSE),
  silent = TRUE)
```

\

Figure 2.4 shows the estimates of the model coefficients with `r ci_level*100`% confidence intervals. The purpose of this graph is to be able to best distinguish between the relative strength of each of the `r options` assessed. As such the coefficient estimates themselves are not directly interpretable, but it can be concluded that a higher value for the coefficient indicates that a `r option` has been ranked as best more often. The `r ci_level*100`% confidence width is chosen so that non-overlapping confidence intervals could be interpreted as indicating significant differences at the alpha = `r sig_level`. This may not match exactly with the mean separation groupings, as these groupings also take into account multiple testing through the Benjamini and Hochberg adjustment [@BHtest].

Mean separation analysis was also conducted to indicate, using letters, which `r options` are significantly more preferred than others in terms of '`r ovname`'. When `r options` have at least one letter in common, there is not enough evidence from the experiment to be confident about their relative order at the alpha = `r sig_level`.

```{r est_plot, dpi=dpi, fig.height=favplot_h, fig.width=5, fig.cap=paste0("Figure 2.4. Plackett-Luce Model estimates (log-worth) of tested ", options, " for '", ovname,"' with ", ci_level*100, "% confidence intervals. Different letters indicate significant differences at p < ", sig_level ,". The ", option, " ", reference, " is set as reference (log-worth arbitrarily set to zero).")}
try(plot_summaries[[reference_trait]],  silent = TRUE)
```

\

The same information in Figure 2.4 is shown in Table 2.3 below.

\

```{r est_table}
try(kable(summaries[[reference_trait]], 
      digits = 4,
      row.names = FALSE,
      caption = paste0("Table 2.3. Plackett-Luce Model estimates (log-worth) of tested ", 
                       options, " for '", ovname,"' with ", ci_level*100, 
                       "% confidence intervals. Different letters indicate significant differences at p < ",
                       sig_level ,". The ", option, " ", reference, 
                       " is set as reference (log-worth arbitrarily set to zero).")),
  silent = TRUE)
```

\

Table 2.4 and Figure 2.5 use the coefficients from the Plackett-Luce model to estimate the probability of each `r option` being considered to be the top ranked `r option` in a direct comparison between all of the possible `r options`.

\

```{r table3.4}
try(kable(worths[[reference_trait]][,-2],
      row.names = FALSE,
      caption = paste0("Table 2.4. Probability of being the best ranked for '",
      ovname, "'.")),
  silent = TRUE)
```

\

```{r rankedfirst, dpi=dpi, fig.height=favplot_h, fig.width=5, fig.cap= paste0("Figure 2.5. Probability of being the best ranked for '", ovname, "'.")}
try(plot_worth_bar(worths[[reference_trait]], value = "Worth", group = Option),
  silent = TRUE)
```

\

## Plackett-Luce Model with covariates for `r ovname`  

\

A model-based recursive partitioning method [@Strobl2009] was used to determine which of the covariates, if any, had significant relationships with the rankings of `r ovname`. This approach identifies sub-groups in the data for which the rankings of the different `r options` are significantly different to each other. This analysis required that all rankings and covariates are completely available for the entire dataset. Here we used `r dim(Gdata)[[1]]` out of `r sum(trait_list[[reference_trait]]$keep)` valid rankings for `r ovname`.

```{r drop_covar_statement}
# make the statement if there is any covariate dropped
drop_covar_statement <- ""
if (covarTRUE) {
  if (isTRUE(length(covar_dropped) > 0)) {
    drop_covar_statement <- paste0(
      "The covariates(s) '", paste(covar_dropped, collapse = "', '"),
      "' were not used in the analysis, because they did not surpass ",
      "the threshold of at least ", paste0(missexp * 100, "%"), " valid entries."
    )
  }
  
  if (isTRUE(length(covar_dropped) == 0)) {
    drop_covar_statement <- ""
  }
}
```

`r  paste(drop_covar_statement, collapse='\n')`

\

```{r}
effect_covar_statement1 <- ""
effect_covar_statement2 <- ""
if (isTRUE(length(tree_f) > 1))  {
  if (isTRUE(any(na.omit(outtabs[[1]]$p.value) < sig_level_tree))) {
    effect_covar_statement1 <- 
      paste("The p-values for each of the covariates tested,", 
            "one-by-one, showing whether or not the covariate could be used", 
            "to define sub-groups with significantly different rankings are",
            "shown in Table 2.6")
    
    effect_covar_statement3 <-
      paste("The partitioning of the rankings based on the most significantly", 
        "sub-groups which were identified from the data using an alpha =", 
        sig_level_tree, "is shown in Figure 12. At the top of the tree is the", 
        "full dataset, then working down through the different levels of", 
        "the tree shows the combinations of variables which define each", 
        "subgroup. The model parameters are shown for the final subgroups", 
        "in the plot at the bottom of the tree. The model quasi-variance", 
        "estimates, along with", ci_level*100, "% confidence intervals are", 
        "provided. This will help identification of which", options, 
        "were better suited to particular sub-groups identified by the analysis.")
  }
  
}
```

`r  paste(effect_covar_statement1, collapse='\n')`

```{r univar_pval}
if (isTRUE(length(na.omit(outtabs[[1]]$p.value)) > 0)){
try(kable(uni_sum,
      caption = paste0("Table 2.6. Univariate p-values for first split in ",
                       "Plackett-Luce tree model for the trait '",
                       ovname, "'."),
      row.names = FALSE),
  silent = TRUE)
}
```

\

```{r node_statement} 
# node statement
node_statement <- ""

if (isTRUE(length(tree_f) > 1)){
node_statement <- paste("Table 2.7 shows which", options,
                        "where identified as the best and worst ranked in the", 
                        "subgroups identified by the Plackett-Luce tree for the trait '", 
                        ovname ,"'.")
}
```

`r  paste(node_statement, collapse='\n')`

\

```{r subgroups-found}
if(isTRUE(length(tree_f) > 1)){
  try(
    kable(node_summary, 
        caption = paste0("Table 2.7. Summary of different subgroups identified",
                         " by the Plackett-Luce model."),
        row.names = FALSE),
    silent = TRUE)
}

```

\

`r  paste(effect_covar_statement2, collapse='\n')`

```{r no_tree}
no_tree <- ""
if (isTRUE(length(tree_f) == 1)) {
  no_tree <- 
    paste0("No split was found for the Plackett-Luce tree using the selected ",
    "covariates. Figure 8 shows the model for the rankings provided in this ",
    "project, showing that none of the tested covariates had a clear influence on ",
    "the rankings of '", ovname, "' with an alpha = ", sig_level_tree,".")
}
```

\

`r paste(no_tree, collapse='\n')`

\

```{r pltree_legend}
pltree_text <- paste0("Figure 2.6. Plackett-Luce tree for '", ovname, "'. The horizontal axis is the probability of winning. Error bars show quasi-SEs. The gray vertical line indicates the average probability of winning (1/number of ", options, ").")

if (length(tree_f) > 1) {
  pltree_text <- paste0(pltree_text, " Nodes split by the following covariate and attribute ", paste(paste("Node ", node_ids, node_summary[,1]), collapse = ", and "), ".")
}

```

```{r pltree, dpi=500, asis=TRUE,fig.height=8,fig.width=10, fig.cap = pltree_text}
try(plottree, silent = TRUE)
```

\

# Section 3: Other traits

```{r other_chars}
other_chars <- paste0("This report only assessed the trait '", ovname, "'.")

if (isTRUE(nothertraits > 0)) {
  other_chars <- 
  paste0("Data analysis summaries are also shown for the ", 
         "other ", nothertraits," traits assessed in this project.")
} 
```

`r paste(other_chars, collapse='\n')`

\

```{r, other_chars_analysis}
trait_summaries <- ""
if(isTRUE(nothertraits > 0)) {
  
  trait_list <- trait_list[-reference_trait]
  fav_traits <- fav_traits[-reference_trait]
  vic_traits <- vic_traits[-reference_trait]
  aov_tables <- aov_tables[-reference_trait]
  plot_summaries <- plot_summaries[-reference_trait]
  summaries <- summaries[-reference_trait]
  worths <- worths[-reference_trait]
  
  for(i in seq_len(nothertraits)){
    trait_summaries<-c(trait_summaries,
                       knitr::knit_child(paste0(fullpath, "/report/other_trait_summaries.Rmd"), 
                                         quiet=TRUE))
}  
}

```

```{r other_chars_include, echo=FALSE, results="asis", message=FALSE, warning=FALSE}
cat(paste(trait_summaries, collapse = '\n'))
```

\pagebreak

```{r error}
e <- ""
if (isFALSE(is.null(error))){
  e <- paste("During the execution of the requested analysis",
             "we also found the following error(s) that disabled",
             "the production of some outputs.",
             "Please report the error(s) to the ClimMob Team, via the",
             "'Chat bot' in your ClimMob account.")
}
```

`r paste(e, collapse = '\n')`

```{r error2}
if (isFALSE(is.null(error))){
print(error)
}
```


\pagebreak

# References

